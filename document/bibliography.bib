@Article{ijgi11020117,
AUTHOR = {Car, Nicholas J. and Homburg, Timo},
TITLE = {GeoSPARQL 1.1: Motivations, Details and Applications of the Decadal Update to the Most Important Geospatial LOD Standard},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {11},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {117},
URL = {https://www.mdpi.com/2220-9964/11/2/117},
ISSN = {2220-9964},
ABSTRACT = {In 2012, the Open Geospatial Consortium published GeoSPARQL defining “an RDF/OWL ontology for [spatial] information”, “SPARQL extension functions” for performing spatial operations on RDF data and “RIF rules” defining entailments to be drawn from graph pattern matching. In the 8+ years since its publication, GeoSPARQL has become the most important spatial Semantic Web standard, as judged by references to it in other Semantic Web standards and its wide use for Semantic Web data. An update to GeoSPARQL was proposed in 2019 to deliver a version 1.1 with a charter to: handle outstanding change requests and source new ones from the user community and to “better present” the standard, that is to better link all the standard’s parts and better document and exemplify elements. Expected updates included new geometry representations, alignments to other ontologies, handling of new spatial referencing systems, and new artifact presentation. This paper describes motivating change requests and actual resultant updates in the candidate version 1.1 of the standard alongside reference implementations and usage examples. We also describe the theory behind particular updates, initial implementations of many parts of the standard, and our expectations for GeoSPARQL 1.1’s use.},
DOI = {10.3390/ijgi11020117}
}
@article{sikos2017novel,
author = {Sikos, Leslie F.},
title = {A novel ontology for 3D semantics: ontology-based 3D model indexing and content-based video retrieval applied to the medical domain},
journal = {International Journal of Metadata, Semantics and Ontologies},
volume = {12},
number = {1},
pages = {59-70},
year = {2017},
doi = {10.1504/IJMSO.2017.087702},
URL = {https://www.inderscienceonline.com/doi/abs/10.1504/IJMSO.2017.087702},
eprint = {https://www.inderscienceonline.com/doi/pdf/10.1504/IJMSO.2017.087702},
abstract = {Because of the growing popularity of 3D modelling, there is a great demand for efficient mechanisms to automatically process 3D contents. Owing to the lack of semantics, however, most 3D scenes cannot be interpreted by software agents. 3D ontologies can provide formal definitions for 3D objects; however, many of them are semi-structured only, cover a narrow knowledge domain, do not provide comprehensive coverage for geometric primitives, and do not exploit the full expressivity of the implementation language. This paper presents the most comprehensive formally grounded 3D ontology to date that maps the entire XSD-based vocabulary of the industry standard X3D (ISO/IEC 19775-19777) to OWL 2, complemented by fundamental concepts and roles of the 3D modelling industry not covered by X3D. This upper ontology can be used for the representation, annotation, and efficient indexing of 3D models, and their retrieval by 3D characteristics rather than by associated category labels. }
}
@article{chadzynski2023semantic,
title={Semantic 3D city interfaces—Intelligent interactions on dynamic geospatial knowledge graphs},
volume={4},
DOI={10.1017/dce.2023.14},
journal={Data-Centric Engineering},
author={Chadzynski, Arkadiusz and Li, Shiying and Grišiūtė, Ayda and Chua, Jefferson and Hofmeister, Markus and Yan, Jingya and Tai, Huay Yi and Lloyd, Emily and Tsai, Yi Kai and Agarwal, Mehal and et al.}, 
year={2023}, 
pages={e20}
}
@article{ropelewski_standard_2022,
	title = {Standard metadata for 3D microscopy},
	volume = {9},
	issn = {2052-4463},
	url = {http://europepmc.org/abstract/MED/35896564},
	doi = {10.1038/s41597-022-01562-5},
	abstract = {Recent advances in fluorescence microscopy techniques and tissue clearing, labeling, and staining provide unprecedented opportunities to investigate brain structure and function. These experiments' images make it possible to catalog brain cell types and define their location, morphology, and connectivity in a native context, leading to a better understanding of normal development and disease etiology. Consistent annotation of metadata is needed to provide the context necessary to understand, reuse, and integrate these data. This report describes an effort to establish metadata standards for three-dimensional (3D) microscopy datasets for use by the Brain Research through Advancing Innovative Neurotechnologies® (BRAIN) Initiative and the neuroscience research community. These standards were built on existing efforts and developed with input from the brain microscopy community to promote adoption. The resulting 3D Microscopy Metadata Standards (3D-MMS) includes 91 fields organized into seven categories: Contributors, Funders, Publication, Instrument, Dataset, Specimen, and Image. Adoption of these metadata standards will ensure that investigators receive credit for their work, promote data reuse, facilitate downstream analysis of shared data, and encourage collaboration.},
	language = {eng},
	number = {1},
	journal = {Scientific data},
	author = {Ropelewski, Alexander J and Rizzo, Megan A and Swedlow, Jason R and Huisken, Jan and Osten, Pavel and Khanjani, Neda and Weiss, Kurt and Bakalov, Vesselina and Engle, Michelle and Gridley, Lauren and Krzyzanowski, Michelle and Madden, Tom and Maiese, Deborah and Mandal, Meisha and Waterfield, Justin and Williams, David and Hamilton, Carol M and Huggins, Wayne},
	month = jul,
	year = {2022},
	keywords = {Metadata, Microscopy},
	pages = {449},
}
@misc{hansson2024citygml,
  abstract     = {CityGML is an important standard to present 3D geometry, topology, semantics and appearance that together with 3D city models, which have had increased use within analysis and applications, such as emergency response, energy consumption and occupancy measurement. However, the standard’s querying and integration capabilities can still be further explored. One way to do this is through the Semantic Web technology knowledge graphs (KG). Proof-of-concept studies have been made using this approach but remains to be properly applied outside of studies as ad-hoc and data conversion approaches are still the most prevalent in practice. The approach can potentially be applied to fields such as the building permit process and transport infrastructure management as means to further help the digitalization in these fields and improve the workflows by allowing seamless linking and integration of other data while being queriable. This study provides a demonstration in how CityGML data can be presented as a virtual knowledge graph (VKG) in an effective manner through the commonly used tools 3DCityDB and Protégé with the Ontop plugin. This provides a means to improve interoperability between different types of data as well as a method to better manage semantical 3D city models. A framework is described in this study to populate the commonly used CityGML 2.0 ontology with CityGML data containing buildings from an area in Malmö, Sweden. This is primarily done through the use of R2RML mapping that retrieves the CityGML data from a 3DCityDB relational database to create virtual instances of data based on the CityGML ontology, thus exposing the data as a VKG through the Ontop system. To ensure that the data is effectively represented and demonstrated, SPARQL queries were performed to validate and test the KG. Seven queries were made in total to test different parts of the KG and to demonstrate some practical implications of the approach. The resulting KG constructed from the mapping retrieves the expected results through the queries, based on comparisons with the original data. As a result, it can be concluded that the CityGML data is effectively represented in the KG. Most notably, the showcasing of the mapping for LoD3 buildings provides a novel description of the implementation process. The framework described is sufficient for the representation despite the limitations imposed by the 3DCityDB database schema and Protégé suite while also demonstrating the potential use of the approach for urban planning processes.},
  author       = {Hansson, Felix},
  language     = {eng},
  note         = {Student Paper},
  series       = {Student thesis series INES},
  title        = {Linked geodata: CityGML represented as a virtual knowledge graph},
  year         = {2024},
}
@ARTICLE{kutzner2020citygml30,
       author = {Kutzner, Tatjana and Chaturvedi, Kanishk and Kolbe, Thomas H.},
        title = "{CityGML 3.0: New Functions Open Up New Applications}",
      journal = {PFG - Journal of Photogrammetry},
         year = 2020,
        month = feb,
       volume = {88},
       number = {1},
        pages = {43-61},
          doi = {10.1007/s41064-020-00095-z},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020PFJ....88...43K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@Article{ijgi12090351,
AUTHOR = {El Yamani, Siham and Hajji, Rafika and Billen, Roland},
TITLE = {IFC-CityGML Data Integration for 3D Property Valuation},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {12},
YEAR = {2023},
NUMBER = {9},
ARTICLE-NUMBER = {351},
URL = {https://www.mdpi.com/2220-9964/12/9/351},
ISSN = {2220-9964},
ABSTRACT = {The accurate assessment of proper value in complex and increasingly high-rise urban environments is a significant challenge. Previous research has identified property value as a composite of indoor elements, such as volume and height, and 3D simulations of the outdoor environment, including variables such as view, noise, and pollution. These simulations have been preliminary performed in taxation context; however, there has been no work addressing the simulation of property valuation. In this paper, we propose an IFC-CityGML data integration approach for property valuation and develop a workflow based on IFC-CityGML 3.0 to simulate and model 3D property variables at the Level of Information Need. We evaluate this approach by testing it for two indoor variables, indoor daylight and property unit cost. Our proposed approach aims to improve the accuracy of property valuation by integrating data from indoor and outdoor environments and providing a standardized and efficient workflow for property valuation modeling using IFC and CityGML. Our approach represents a solid base for future works toward a 3D property valuation extension.},
DOI = {10.3390/ijgi12090351}
}
@article{CHADZYNSKI2021100106,
title = {Semantic 3D City Database — An enabler for a dynamic geospatial knowledge graph},
journal = {Energy and AI},
volume = {6},
pages = {100106},
year = {2021},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2021.100106},
url = {https://www.sciencedirect.com/science/article/pii/S2666546821000574},
author = {Arkadiusz Chadzynski and Nenad Krdzavac and Feroz Farazi and Mei Qi Lim and Shiying Li and Ayda Grisiute and Pieter Herthogs and Aurel {von Richthofen} and Stephen Cairns and Markus Kraft},
keywords = {CityGML, Sustainability, Digitisation, Urban planning, Semantic web, Knowledge graph, Ontology, Decision support system, Artificial intelligence, Geospatial modelling, Geospatial search},
abstract = {This paper presents a dynamic geospatial knowledge graph as part of The World Avatar project, with an underlying ontology based on CityGML 2.0 for three-dimensional geometrical city objects. We comprehensively evaluated, repaired and refined an existing CityGML ontology to produce an improved version that could pass the necessary tests and complete unit test development. A corresponding data transformation tool, originally designed to work alongside CityGML, was extended. This allowed for the transformation of original data into a form of semantic triples. We compared various scalable technologies for this semantic data storage and chose Blazegraph™ as it provided the required geospatial search functionality. We also evaluated scalable hardware data solutions and file systems using the publicly available CityGML 2.0 data of Charlottenburg in Berlin, Germany as a working example. The structural isomorphism of the CityGML schemas and the OntoCityGML Tbox allowed the data to be transformed without loss of information. Efficient geospatial search algorithms allowed us to retrieve building data from any point in a city using coordinates. The use of named graphs and namespaces for data partitioning ensured the system performance stayed well below its capacity limits. This was achieved by evaluating scalable and dedicated data storage hardware capable of hosting expansible file systems, which strengthened the architectural foundations of the target system.}
}
@article{flotynski2017ontology,
author = {Flotyński, Jakub and Walczak, Krzysztof},
title = {Ontology-Based Representation and Modelling of Synthetic 3D Content: A State-of-the-Art Review},
journal = {Computer Graphics Forum},
volume = {36},
number = {8},
pages = {329-353},
keywords = {Computer graphics I.3.7: Three-Dimensional Graphics and Realism, Virtual reality; Information interfaces and presentation H.5.1: Multimedia information systems, Artificial augmented and virtual realities; Information interfaces and presentation H.5.2: User Interfaces, Graphical user interfaces (GUI) Virtual reality},
doi = {https://doi.org/10.1111/cgf.13083},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13083},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13083},
abstract = {Abstract An indispensable element of any practical 3D/VR/AR application is synthetic three-dimensional (3D) content. Such content is characterized by a variety of features—geometry, structure, space, appearance, animation and behaviour—which makes the modelling of 3D content a much more complex, difficult and time-consuming task than in the case of other types of content. One of the promising research directions aiming at simplification of modelling 3D content is the use of the semantic web approach. The formalism provided by semantic web techniques enables declarative knowledge-based modelling of content based on ontologies. Such modelling can be conducted at different levels of abstraction, possibly domain-specific, with inherent separation of concerns. The use of semantic web ontologies enables content representation independent of particular presentation platforms and facilitates indexing, searching and analysing content, thus contributing to increased content re-usability. A range of approaches have been proposed to permit semantic representation and modelling of synthetic 3D content. These approaches differ in the methodologies and technologies used as well as their scope and application domains. This paper provides a review of the current state of the art in representation and modelling of 3D content based on semantic web ontologies, together with a classification, characterization and discussion of the particular approaches.},
year = {2017}
}
@INPROCEEDINGS{perzylo2015ontology,
  author={Perzylo, Alexander and Somani, Nikhil and Rickert, Markus and Knoll, Alois},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={An ontology for CAD data and geometric constraints as a link between product models and semantic robot task descriptions}, 
  year={2015},
  pages={4197-4203},
  keywords={Design automation;Solid modeling;Semantics;OWL;Mathematical model;Wires;Ontologies},
  doi={10.1109/IROS.2015.7353971}
}
@Article{yuchen2025ontology,
  author={Yuchen Wang and Xinheng Wang and Ang Liu and Junqing Zhang and Jinhua Zhang},
  title={{Ontology of 3D virtual modeling in digital twin: a review, analysis and thinking}},
  journal={Journal of Intelligent Manufacturing},
  year=2025,
  volume={36},
  number={1},
  pages={95-145},
  month={January},
  keywords={Real-time cyber-physical system; Autonomous 3D reconstruction; Model validation and analysis; Real-t},
  doi={10.1007/s10845-023-02246-6},
  abstract={The pervasive smart manufacturing is bringing increasing attention to digital twin. As a core part of virtual modeling, 3D virtual modeling is crucial to improve the intuitiveness of state monitoring, enhance human-cyber interactions, visualize conditions and simulations, and provide visual guides in digital twin. However, although 3D virtual modeling in digital twin has many benefits for different applications, its complex characteristics become obstacles for novice engineers to develop and utilize. Besides, research information about 3D virtual modeling in digital twin is too scattered, while there has been no literature review that specially and comprehensively summarizes and analyzes it. To help novice engineers understand and scheme 3D virtual modeling in digital twin for future research and applications, this paper reviews 106 digital twin 3D modeling cases with their characteristics, including deployment targets, purposes \& roles, collaborative models, data flows, the autonomy of 3D modeling, fidelity, twinning rates, enabling technologies, and enabling tools. This paper then discusses and analyzes the review outcomes via statistics. Finally, this paper also proposes a thinking map for scheming the 3D virtual modeling in digital twin. In general, 3D virtual modeling is oriented by the motivation behind different digital twins, engineers hence should reflect on the purposes, scenarios, resources, and long-term visions of their projects. When designing characteristics of 3D virtual modeling, engineers must consider functions, capabilities of data processing and transmission, timeliness of data, applicability, and specialty of each characteristic. For future work, this paper highlights three important research issues to realize the prospect of 3D virtual modeling, including the versatility of autonomous 3D modeling, incremental updates of 3D models, and optimal planning of data collections for 3D modeling. Besides, future work will also investigate the enhancem},
  url={https://ideas.repec.org/a/spr/joinma/v36y2025i1d10.1007_s10845-023-02246-6.html}
}